{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This scripts takes about 1 1/2 minutes seconds to execute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea of this notebook is to create a first (simple) DL model using all the same features used in the multinomial logit model.\n",
    "\n",
    "Much inspiration was derived from https://towardsdatascience.com/use-machine-learning-to-predict-horse-racing-4f1111fb6ced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from importlib import reload\n",
    "import deeplearninglib\n",
    "reload(deeplearninglib)\n",
    "from deeplearninglib import *\n",
    "\n",
    "import wandb\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model to train\n",
    "\n",
    "model_inventory = {'mktprob': {'XZ_columns': [\"mkt_prob\"],\n",
    "                               'continuous_features': [\"mkt_prob\"],\n",
    "                               'learning_rate': 10e-1,\n",
    "                               'epochs': 50,\n",
    "                               'vacant_stall_indicator': False,\n",
    "                               'bias': True,\n",
    "                               'model_architecture': LinSig},\n",
    "                   'mktprob_soft': {'XZ_columns': [\"mkt_prob\"],\n",
    "                               'continuous_features': [\"mkt_prob\"],\n",
    "                               'learning_rate': 10e-1,\n",
    "                               'epochs': 50,\n",
    "                               'vacant_stall_indicator': False,\n",
    "                               'bias': True,\n",
    "                               'model_architecture': LinSoft},\n",
    "                    'mktprob_MLR': {'XZ_columns': [\"mkt_prob\"],\n",
    "                               'continuous_features': [\"mkt_prob\"],\n",
    "                               'learning_rate': 10e-1,\n",
    "                               'epochs': 50,\n",
    "                               'vacant_stall_indicator': False,\n",
    "                               'bias': True,\n",
    "                               'model_architecture': MLR},\n",
    "                   'AlunOwen_v0': {'XZ_columns': [\"age\", \"sire_sr\", \"dam_sr\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"visor\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [\"age\", \"sire_sr\", \"dam_sr\", \"trainer_sr\", \"daysLTO\"],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': True,\n",
    "                                   'model_architecture': LinSig},\n",
    "                   'AlunOwen_v1': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [\"age\", \"trainer_sr\", \"daysLTO\"],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': True,\n",
    "                                   'model_architecture': LinSig},\n",
    "                   'AlunOwen_v2': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [\"age\", \"trainer_sr\", \"daysLTO\"],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': True,\n",
    "                                   'model_architecture': LinDropReluLinSoft},\n",
    "                   'AlunOwen_v3': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [\"age\", \"trainer_sr\", \"daysLTO\"],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': False,\n",
    "                                   'model_architecture': MLR},\n",
    "                   'AlunOwen_v4': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': False,\n",
    "                                   'model_architecture': MLR},\n",
    "                   'test_v1': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\", \"course_Kempton\", \"course_Lingfield\", \"course_Southwell\", \"course_Wolverhampton\", \"going_Firm\", \"going_Good\", \"going_Good to Firm\", \"going_Good to Soft\", \"going_Slow\", \"going_Soft\", \"going_Standard\", \"going_Standard to Slow\", \"direction_Left Handed\", \"direction_Right Handed\"],\n",
    "                                   'continuous_features': [],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': False,\n",
    "                                   'model_architecture': LinDropReluLinSoft}\n",
    "                               }\n",
    "\n",
    "model = 'AlunOwen_v3'\n",
    "XZ_columns = model_inventory[model]['XZ_columns']\n",
    "continuous_features = model_inventory[model]['continuous_features']\n",
    "learning_rate = model_inventory[model]['learning_rate']\n",
    "epochs = model_inventory[model]['epochs']\n",
    "vacant_stall_indicator = model_inventory[model]['vacant_stall_indicator']\n",
    "bias = model_inventory[model]['bias']\n",
    "model_architecture = model_inventory[model]['model_architecture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "y_columns = [\"win\"] # assumed to be contained in runners files\n",
    "\n",
    "runners_train_data_fn = \"data\\\\runners_train.csv\"\n",
    "races_train_data_fn = \"data\\\\races_train.csv\"\n",
    "runners_validate_data_fn = \"data\\\\runners_validate.csv\"\n",
    "races_validate_data_fn = \"data\\\\races_validate.csv\"\n",
    "\n",
    "train_data = RacesDataset(runners_train_data_fn, races_train_data_fn, XZ_columns, y_columns, vacant_stall_indicator=vacant_stall_indicator, continuous_features=continuous_features)\n",
    "validate_data = RacesDataset(runners_validate_data_fn, races_validate_data_fn, XZ_columns, y_columns, vacant_stall_indicator=vacant_stall_indicator, scalar=train_data.scalar, continuous_features=continuous_features)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "validate_dataloader = DataLoader(validate_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare and save test data for use by Dividend Project Model; then delete them to ensure they're not used during training or validation\n",
    "\n",
    "# note, test data is model-specific\n",
    "\n",
    "runners_test_data_fn = \"data\\\\runners_test.csv\"\n",
    "races_test_data_fn = \"data\\\\races_test.csv\"\n",
    "\n",
    "test_data = RacesDataset(runners_test_data_fn, races_test_data_fn, XZ_columns, y_columns, vacant_stall_indicator=vacant_stall_indicator, scalar=train_data.scalar, continuous_features=continuous_features)\n",
    "\n",
    "torch.save(test_data, \"data\\\\\" + model + \"_test_data.pt\")\n",
    "\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"16\" halign=\"left\">age</th>\n",
       "      <th colspan=\"16\" halign=\"left\">blinkers</th>\n",
       "      <th colspan=\"16\" halign=\"left\">cheekpieces</th>\n",
       "      <th colspan=\"16\" halign=\"left\">daysLTO</th>\n",
       "      <th colspan=\"16\" halign=\"left\">entire</th>\n",
       "      <th colspan=\"16\" halign=\"left\">gelding</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position1_1</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position1_2</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position1_3</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position1_4</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position2_1</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position2_2</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position2_3</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position2_4</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position3_1</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position3_2</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position3_3</th>\n",
       "      <th colspan=\"16\" halign=\"left\">position3_4</th>\n",
       "      <th colspan=\"16\" halign=\"left\">tonguetie</th>\n",
       "      <th colspan=\"16\" halign=\"left\">trainer_sr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stall_number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11504</th>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>5.831936</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11505</th>\n",
       "      <td>-0.140729</td>\n",
       "      <td>0.920958</td>\n",
       "      <td>2.513488</td>\n",
       "      <td>1.451801</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>1.982644</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11506</th>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11507</th>\n",
       "      <td>0.390115</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>1.982644</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11508</th>\n",
       "      <td>1.451801</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>0.390115</td>\n",
       "      <td>-0.140729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>1.638658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>5.831936</td>\n",
       "      <td>-1.748939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   age                                                    \\\n",
       "stall_number        1         2         3         4         5         6    \n",
       "race_id                                                                    \n",
       "11504        -0.671572 -0.671572 -0.671572 -0.671572 -0.671572 -0.671572   \n",
       "11505        -0.140729  0.920958  2.513488  1.451801  0.390115  1.982644   \n",
       "11506        -0.671572 -0.671572 -0.671572 -0.671572 -0.671572 -0.671572   \n",
       "11507         0.390115 -0.140729 -0.140729 -0.140729 -0.140729 -0.140729   \n",
       "11508         1.451801 -0.140729  0.390115 -0.140729  0.390115 -0.140729   \n",
       "\n",
       "                                                                               \\\n",
       "stall_number        7         8         9         10        11   12   13   14   \n",
       "race_id                                                                         \n",
       "11504        -0.671572 -0.671572  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
       "11505         0.390115  0.390115  0.390115 -0.140729  0.390115  0.0  0.0  0.0   \n",
       "11506        -0.671572 -0.671572 -0.671572 -0.671572  0.000000  0.0  0.0  0.0   \n",
       "11507         1.982644 -0.140729 -0.140729  0.000000  0.000000  0.0  0.0  0.0   \n",
       "11508         0.390115  0.390115 -0.140729  0.000000  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "                       blinkers                                               \\\n",
       "stall_number   15   16       1    2    3    4    5    6    7    8    9    10   \n",
       "race_id                                                                        \n",
       "11504         0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0      1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                           cheekpieces                      \\\n",
       "stall_number   11   12   13   14   15   16          1    2    3    4    5    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  1.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0         0.0  1.0  1.0  0.0  0.0   \n",
       "\n",
       "                                                                      daysLTO  \\\n",
       "stall_number   6    7    8    9    10   11   12   13   14   15   16        1    \n",
       "race_id                                                                         \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.638658   \n",
       "11505         0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.638658   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.638658   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.638658   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.638658   \n",
       "\n",
       "                                                                          \\\n",
       "stall_number        2         3         4         5         6         7    \n",
       "race_id                                                                    \n",
       "11504         1.638658  1.638658  1.638658  1.638658  1.638658  1.638658   \n",
       "11505         1.638658  1.638658  1.638658  1.638658  1.638658  1.638658   \n",
       "11506         1.638658  1.638658  1.638658  1.638658  1.638658  1.638658   \n",
       "11507         1.638658  1.638658  1.638658  1.638658  1.638658  1.638658   \n",
       "11508         1.638658  1.638658  1.638658  1.638658  1.638658  1.638658   \n",
       "\n",
       "                                                                               \\\n",
       "stall_number        8         9         10        11   12   13   14   15   16   \n",
       "race_id                                                                         \n",
       "11504         1.638658  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         1.638658  1.638658  1.638658  1.638658  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         1.638658  1.638658  1.638658  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         1.638658  1.638658  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         1.638658  1.638658  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "             entire                                                         \\\n",
       "stall_number     1    2    3    4    5    6    7    8    9    10   11   12   \n",
       "race_id                                                                      \n",
       "11504           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506           0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "11507           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                 gelding                                     \\\n",
       "stall_number   13   14   15   16      1    2    3    4    5    6    7    8    \n",
       "race_id                                                                       \n",
       "11504         0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "11505         0.0  0.0  0.0  0.0     0.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0     1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                                     position1_1            \\\n",
       "stall_number   9    10   11   12   13   14   15   16          1    2    3    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0   \n",
       "11505         1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0   \n",
       "\n",
       "                                                                               \\\n",
       "stall_number   4    5    6    7    8    9    10   11   12   13   14   15   16   \n",
       "race_id                                                                         \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "             position1_2                                                    \\\n",
       "stall_number          1    2    3    4    5    6    7    8    9    10   11   \n",
       "race_id                                                                      \n",
       "11504                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                      position1_3                           \\\n",
       "stall_number   12   13   14   15   16          1    2    3    4    5    6    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                                               position1_4  \\\n",
       "stall_number   7    8    9    10   11   12   13   14   15   16          1    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "\n",
       "                                                                               \\\n",
       "stall_number   2    3    4    5    6    7    8    9    10   11   12   13   14   \n",
       "race_id                                                                         \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                       position2_1                                          \\\n",
       "stall_number   15   16          1    2    3    4    5    6    7    8    9    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                                position2_2                 \\\n",
       "stall_number   10   11   12   13   14   15   16          1    2    3    4    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                                                          \\\n",
       "stall_number   5    6    7    8    9    10   11   12   13   14   15   16   \n",
       "race_id                                                                    \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "             position2_3                                                    \\\n",
       "stall_number          1    2    3    4    5    6    7    8    9    10   11   \n",
       "race_id                                                                      \n",
       "11504                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                      position2_4                           \\\n",
       "stall_number   12   13   14   15   16          1    2    3    4    5    6    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                                               position3_1  \\\n",
       "stall_number   7    8    9    10   11   12   13   14   15   16          1    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0   \n",
       "\n",
       "                                                                               \\\n",
       "stall_number   2    3    4    5    6    7    8    9    10   11   12   13   14   \n",
       "race_id                                                                         \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                       position3_2                                          \\\n",
       "stall_number   15   16          1    2    3    4    5    6    7    8    9    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                                position3_3                 \\\n",
       "stall_number   10   11   12   13   14   15   16          1    2    3    4    \n",
       "race_id                                                                      \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0         0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                                                          \\\n",
       "stall_number   5    6    7    8    9    10   11   12   13   14   15   16   \n",
       "race_id                                                                    \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "             position3_4                                                    \\\n",
       "stall_number          1    2    3    4    5    6    7    8    9    10   11   \n",
       "race_id                                                                      \n",
       "11504                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                      tonguetie                                \\\n",
       "stall_number   12   13   14   15   16        1    2    3    4    5    6    7    \n",
       "race_id                                                                         \n",
       "11504         0.0  0.0  0.0  0.0  0.0       0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11505         0.0  0.0  0.0  0.0  0.0       0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11506         0.0  0.0  0.0  0.0  0.0       0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11507         0.0  0.0  0.0  0.0  0.0       0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "11508         0.0  0.0  0.0  0.0  0.0       0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                                          trainer_sr  \\\n",
       "stall_number   8    9    10   11   12   13   14   15   16         1    \n",
       "race_id                                                                \n",
       "11504         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -1.748939   \n",
       "11505         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -1.748939   \n",
       "11506         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -1.748939   \n",
       "11507         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -1.748939   \n",
       "11508         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -1.748939   \n",
       "\n",
       "                                                                          \\\n",
       "stall_number        2         3         4         5         6         7    \n",
       "race_id                                                                    \n",
       "11504        -1.748939  5.831936 -1.748939 -1.748939 -1.748939 -1.748939   \n",
       "11505        -1.748939 -1.748939 -1.748939 -1.748939 -1.748939 -1.748939   \n",
       "11506        -1.748939 -1.748939 -1.748939 -1.748939 -1.748939 -1.748939   \n",
       "11507        -1.748939 -1.748939 -1.748939 -1.748939 -1.748939 -1.748939   \n",
       "11508        -1.748939 -1.748939 -1.748939 -1.748939 -1.748939 -1.748939   \n",
       "\n",
       "                                                                               \n",
       "stall_number        8         9         10        11   12   13   14   15   16  \n",
       "race_id                                                                        \n",
       "11504        -1.748939  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "11505        -1.748939 -1.748939 -1.748939 -1.748939  0.0  0.0  0.0  0.0  0.0  \n",
       "11506        -1.748939 -1.748939 -1.748939  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "11507        -1.748939 -1.748939  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
       "11508         5.831936 -1.748939  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 1000 # was 20\n",
    "train_data.runners_wide.loc[:, train_data.X_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11504</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11505</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11506</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11507</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11508</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [11504, 11505, 11506, 11507, 11508]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert model_architecture != \"MLR\" or train_data.races is None, \"Use of MLR with race-specific variables isn't yet supported\"\n",
    "train_data.races.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: AlunOwen_v3\n",
      "Layer: neural_network.0.weights | Size: torch.Size([20]) | Values : Parameter containing:\n",
      "tensor([-0.0040,  0.2867, -0.4399, -0.3934, -0.2059,  0.1433, -0.0106,  0.4238,\n",
      "        -0.0474,  0.1414, -0.1615, -0.1051, -0.5107, -0.3540, -0.2203,  0.0198,\n",
      "         0.2113,  0.3207, -0.3624, -0.2328], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the neural network\n",
    "\n",
    "output_layer_nodes = train_data.y.shape[1]\n",
    "if train_data.Z is not None:\n",
    "    input_layer_nodes = train_data.X.shape[1] + train_data.Z.shape[1]\n",
    "else:\n",
    "    input_layer_nodes = train_data.X.shape[1]\n",
    "\n",
    "torch.manual_seed(0)\n",
    "net = model_architecture(input_layer_nodes, output_layer_nodes, bias=bias).to(device) # linear-relu-linear-softwax nn (1 hidden layer)\n",
    "print(f\"Model structure: {model}\")\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([14])\n",
      "torch.Size([1, 320])\n"
     ]
    }
   ],
   "source": [
    "# example to show how model is used from prediction\n",
    "\n",
    "inputs = torch.rand(1, input_layer_nodes, device=device)\n",
    "logits = net(inputs)\n",
    "y_pred = logits.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME='C:\\Users\\gille\\OneDrive\\1-Projects\\_Horse Racing 2H22\\New Framework\\3b_Deep Learning.ipynb'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gille\\OneDrive\\1-Projects\\_Horse Racing 2H22\\New Framework\\wandb\\run-20230508_093852-jazil65d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gillenpj/horse-racing-project/runs/jazil65d' target=\"_blank\">deft-moon-198</a></strong> to <a href='https://wandb.ai/gillenpj/horse-racing-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gillenpj/horse-racing-project' target=\"_blank\">https://wandb.ai/gillenpj/horse-racing-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gillenpj/horse-racing-project/runs/jazil65d' target=\"_blank\">https://wandb.ai/gillenpj/horse-racing-project/runs/jazil65d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gillenpj/horse-racing-project/runs/jazil65d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x24b42100710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env WANDB_NOTEBOOK_NAME 'C:\\Users\\gille\\OneDrive\\1-Projects\\_Horse Racing 2H22\\New Framework\\3b_Deep Learning.ipynb'\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"horse-racing-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"device\": device,\n",
    "    \"model\": model,\n",
    "    \"XZ_columns\": XZ_columns,\n",
    "    \"continuous_featurs\": continuous_features,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epochs\": epochs,\n",
    "    \"vacant_stall_indicator\": vacant_stall_indicator,\n",
    "    \"bias\": bias,\n",
    "    \"model_architecture\": list(net.modules())\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.776936  [   64/15874]\n",
      "loss: 2.763041  [ 6464/15874]\n",
      "loss: 2.803309  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 10.4%, Avg loss: 2.778028 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.776970  [   64/15874]\n",
      "loss: 2.760748  [ 6464/15874]\n",
      "loss: 2.800752  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 11.0%, Avg loss: 2.776055 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.776941  [   64/15874]\n",
      "loss: 2.758337  [ 6464/15874]\n",
      "loss: 2.798066  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 11.9%, Avg loss: 2.773952 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.776816  [   64/15874]\n",
      "loss: 2.755800  [ 6464/15874]\n",
      "loss: 2.795234  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 12.6%, Avg loss: 2.771704 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.776550  [   64/15874]\n",
      "loss: 2.753131  [ 6464/15874]\n",
      "loss: 2.792241  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 13.3%, Avg loss: 2.769292 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.776078  [   64/15874]\n",
      "loss: 2.750326  [ 6464/15874]\n",
      "loss: 2.789062  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 14.2%, Avg loss: 2.766697 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.775314  [   64/15874]\n",
      "loss: 2.747388  [ 6464/15874]\n",
      "loss: 2.785671  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 14.9%, Avg loss: 2.763895 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.774147  [   64/15874]\n",
      "loss: 2.744333  [ 6464/15874]\n",
      "loss: 2.782032  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 15.7%, Avg loss: 2.760864 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.772448  [   64/15874]\n",
      "loss: 2.741191  [ 6464/15874]\n",
      "loss: 2.778111  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 16.7%, Avg loss: 2.757588 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.770092  [   64/15874]\n",
      "loss: 2.738012  [ 6464/15874]\n",
      "loss: 2.773879  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 17.2%, Avg loss: 2.754061 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.767028  [   64/15874]\n",
      "loss: 2.734864  [ 6464/15874]\n",
      "loss: 2.769347  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 17.7%, Avg loss: 2.750304 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.763354  [   64/15874]\n",
      "loss: 2.731813  [ 6464/15874]\n",
      "loss: 2.764599  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 18.3%, Avg loss: 2.746370 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.759362  [   64/15874]\n",
      "loss: 2.728900  [ 6464/15874]\n",
      "loss: 2.759809  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 18.6%, Avg loss: 2.742341 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.755444  [   64/15874]\n",
      "loss: 2.726124  [ 6464/15874]\n",
      "loss: 2.755194  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 19.0%, Avg loss: 2.738316 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.751939  [   64/15874]\n",
      "loss: 2.723458  [ 6464/15874]\n",
      "loss: 2.750930  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 19.1%, Avg loss: 2.734386 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2.749040  [   64/15874]\n",
      "loss: 2.720870  [ 6464/15874]\n",
      "loss: 2.747099  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 19.3%, Avg loss: 2.730625 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.746807  [   64/15874]\n",
      "loss: 2.718343  [ 6464/15874]\n",
      "loss: 2.743702  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 19.5%, Avg loss: 2.727079 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.745205  [   64/15874]\n",
      "loss: 2.715879  [ 6464/15874]\n",
      "loss: 2.740692  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 19.7%, Avg loss: 2.723769 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.744147  [   64/15874]\n",
      "loss: 2.713492  [ 6464/15874]\n",
      "loss: 2.738011  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 19.7%, Avg loss: 2.720698 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.743526  [   64/15874]\n",
      "loss: 2.711194  [ 6464/15874]\n",
      "loss: 2.735605  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 19.9%, Avg loss: 2.717856 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.743237  [   64/15874]\n",
      "loss: 2.708997  [ 6464/15874]\n",
      "loss: 2.733428  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 19.9%, Avg loss: 2.715228 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.743188  [   64/15874]\n",
      "loss: 2.706906  [ 6464/15874]\n",
      "loss: 2.731445  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.0%, Avg loss: 2.712796 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.743307  [   64/15874]\n",
      "loss: 2.704920  [ 6464/15874]\n",
      "loss: 2.729624  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.1%, Avg loss: 2.710542 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.743540  [   64/15874]\n",
      "loss: 2.703037  [ 6464/15874]\n",
      "loss: 2.727944  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.1%, Avg loss: 2.708449 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2.743846  [   64/15874]\n",
      "loss: 2.701252  [ 6464/15874]\n",
      "loss: 2.726384  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.2%, Avg loss: 2.706501 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.744196  [   64/15874]\n",
      "loss: 2.699560  [ 6464/15874]\n",
      "loss: 2.724929  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.3%, Avg loss: 2.704683 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.744570  [   64/15874]\n",
      "loss: 2.697954  [ 6464/15874]\n",
      "loss: 2.723566  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.4%, Avg loss: 2.702985 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.744954  [   64/15874]\n",
      "loss: 2.696427  [ 6464/15874]\n",
      "loss: 2.722283  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.5%, Avg loss: 2.701394 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.745338  [   64/15874]\n",
      "loss: 2.694976  [ 6464/15874]\n",
      "loss: 2.721071  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.6%, Avg loss: 2.699900 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.745716  [   64/15874]\n",
      "loss: 2.693594  [ 6464/15874]\n",
      "loss: 2.719923  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.7%, Avg loss: 2.698495 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.746082  [   64/15874]\n",
      "loss: 2.692275  [ 6464/15874]\n",
      "loss: 2.718830  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.7%, Avg loss: 2.697170 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.746435  [   64/15874]\n",
      "loss: 2.691016  [ 6464/15874]\n",
      "loss: 2.717788  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.7%, Avg loss: 2.695919 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.746773  [   64/15874]\n",
      "loss: 2.689812  [ 6464/15874]\n",
      "loss: 2.716791  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.9%, Avg loss: 2.694736 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.747094  [   64/15874]\n",
      "loss: 2.688660  [ 6464/15874]\n",
      "loss: 2.715835  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.0%, Avg loss: 2.693614 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.747398  [   64/15874]\n",
      "loss: 2.687555  [ 6464/15874]\n",
      "loss: 2.714916  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.9%, Avg loss: 2.692549 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.747686  [   64/15874]\n",
      "loss: 2.686494  [ 6464/15874]\n",
      "loss: 2.714031  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 20.9%, Avg loss: 2.691537 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.747957  [   64/15874]\n",
      "loss: 2.685474  [ 6464/15874]\n",
      "loss: 2.713176  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.0%, Avg loss: 2.690572 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.748212  [   64/15874]\n",
      "loss: 2.684492  [ 6464/15874]\n",
      "loss: 2.712349  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.689652 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.748452  [   64/15874]\n",
      "loss: 2.683547  [ 6464/15874]\n",
      "loss: 2.711547  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.688774 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.748678  [   64/15874]\n",
      "loss: 2.682635  [ 6464/15874]\n",
      "loss: 2.710770  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.687933 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.748889  [   64/15874]\n",
      "loss: 2.681755  [ 6464/15874]\n",
      "loss: 2.710014  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.687128 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.749087  [   64/15874]\n",
      "loss: 2.680904  [ 6464/15874]\n",
      "loss: 2.709279  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.2%, Avg loss: 2.686356 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.749272  [   64/15874]\n",
      "loss: 2.680081  [ 6464/15874]\n",
      "loss: 2.708563  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.2%, Avg loss: 2.685615 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.749446  [   64/15874]\n",
      "loss: 2.679283  [ 6464/15874]\n",
      "loss: 2.707864  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.684903 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.749608  [   64/15874]\n",
      "loss: 2.678511  [ 6464/15874]\n",
      "loss: 2.707182  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.684217 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.749760  [   64/15874]\n",
      "loss: 2.677761  [ 6464/15874]\n",
      "loss: 2.706515  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.683557 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.749901  [   64/15874]\n",
      "loss: 2.677033  [ 6464/15874]\n",
      "loss: 2.705863  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.0%, Avg loss: 2.682920 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.750033  [   64/15874]\n",
      "loss: 2.676326  [ 6464/15874]\n",
      "loss: 2.705225  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.0%, Avg loss: 2.682305 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.750156  [   64/15874]\n",
      "loss: 2.675638  [ 6464/15874]\n",
      "loss: 2.704599  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.0%, Avg loss: 2.681711 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.750270  [   64/15874]\n",
      "loss: 2.674968  [ 6464/15874]\n",
      "loss: 2.703986  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.0%, Avg loss: 2.681137 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.750377  [   64/15874]\n",
      "loss: 2.674316  [ 6464/15874]\n",
      "loss: 2.703385  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.680581 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 2.750476  [   64/15874]\n",
      "loss: 2.673680  [ 6464/15874]\n",
      "loss: 2.702795  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.0%, Avg loss: 2.680043 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 2.750567  [   64/15874]\n",
      "loss: 2.673060  [ 6464/15874]\n",
      "loss: 2.702215  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.679522 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 2.750652  [   64/15874]\n",
      "loss: 2.672455  [ 6464/15874]\n",
      "loss: 2.701646  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.679016 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 2.750731  [   64/15874]\n",
      "loss: 2.671864  [ 6464/15874]\n",
      "loss: 2.701086  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.2%, Avg loss: 2.678524 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 2.750803  [   64/15874]\n",
      "loss: 2.671287  [ 6464/15874]\n",
      "loss: 2.700536  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.3%, Avg loss: 2.678047 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 2.750870  [   64/15874]\n",
      "loss: 2.670723  [ 6464/15874]\n",
      "loss: 2.699994  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.2%, Avg loss: 2.677583 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 2.750931  [   64/15874]\n",
      "loss: 2.670171  [ 6464/15874]\n",
      "loss: 2.699461  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.2%, Avg loss: 2.677132 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 2.750987  [   64/15874]\n",
      "loss: 2.669630  [ 6464/15874]\n",
      "loss: 2.698937  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.2%, Avg loss: 2.676694 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 2.751038  [   64/15874]\n",
      "loss: 2.669101  [ 6464/15874]\n",
      "loss: 2.698420  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.2%, Avg loss: 2.676266 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 2.751085  [   64/15874]\n",
      "loss: 2.668583  [ 6464/15874]\n",
      "loss: 2.697912  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.1%, Avg loss: 2.675850 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 2.751127  [   64/15874]\n",
      "loss: 2.668075  [ 6464/15874]\n",
      "loss: 2.697411  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.2%, Avg loss: 2.675444 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 2.751164  [   64/15874]\n",
      "loss: 2.667577  [ 6464/15874]\n",
      "loss: 2.696917  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.3%, Avg loss: 2.675048 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 2.751198  [   64/15874]\n",
      "loss: 2.667088  [ 6464/15874]\n",
      "loss: 2.696430  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.4%, Avg loss: 2.674662 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 2.751228  [   64/15874]\n",
      "loss: 2.666609  [ 6464/15874]\n",
      "loss: 2.695951  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.4%, Avg loss: 2.674285 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 2.751254  [   64/15874]\n",
      "loss: 2.666138  [ 6464/15874]\n",
      "loss: 2.695478  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.4%, Avg loss: 2.673917 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 2.751276  [   64/15874]\n",
      "loss: 2.665676  [ 6464/15874]\n",
      "loss: 2.695011  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.4%, Avg loss: 2.673557 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 2.751296  [   64/15874]\n",
      "loss: 2.665221  [ 6464/15874]\n",
      "loss: 2.694551  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.4%, Avg loss: 2.673205 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 2.751312  [   64/15874]\n",
      "loss: 2.664775  [ 6464/15874]\n",
      "loss: 2.694097  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.5%, Avg loss: 2.672862 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 2.751325  [   64/15874]\n",
      "loss: 2.664336  [ 6464/15874]\n",
      "loss: 2.693649  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.6%, Avg loss: 2.672525 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 2.751334  [   64/15874]\n",
      "loss: 2.663904  [ 6464/15874]\n",
      "loss: 2.693208  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.6%, Avg loss: 2.672196 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 2.751342  [   64/15874]\n",
      "loss: 2.663480  [ 6464/15874]\n",
      "loss: 2.692771  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.6%, Avg loss: 2.671874 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 2.751346  [   64/15874]\n",
      "loss: 2.663062  [ 6464/15874]\n",
      "loss: 2.692341  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.7%, Avg loss: 2.671559 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 2.751348  [   64/15874]\n",
      "loss: 2.662650  [ 6464/15874]\n",
      "loss: 2.691916  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.7%, Avg loss: 2.671250 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 2.751347  [   64/15874]\n",
      "loss: 2.662245  [ 6464/15874]\n",
      "loss: 2.691497  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.7%, Avg loss: 2.670947 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 2.751344  [   64/15874]\n",
      "loss: 2.661847  [ 6464/15874]\n",
      "loss: 2.691083  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.7%, Avg loss: 2.670650 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 2.751338  [   64/15874]\n",
      "loss: 2.661454  [ 6464/15874]\n",
      "loss: 2.690674  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.8%, Avg loss: 2.670359 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 2.751331  [   64/15874]\n",
      "loss: 2.661067  [ 6464/15874]\n",
      "loss: 2.690270  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.8%, Avg loss: 2.670074 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 2.751321  [   64/15874]\n",
      "loss: 2.660685  [ 6464/15874]\n",
      "loss: 2.689872  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 21.9%, Avg loss: 2.669794 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 2.751309  [   64/15874]\n",
      "loss: 2.660309  [ 6464/15874]\n",
      "loss: 2.689478  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.669519 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 2.751295  [   64/15874]\n",
      "loss: 2.659939  [ 6464/15874]\n",
      "loss: 2.689089  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.669250 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 2.751279  [   64/15874]\n",
      "loss: 2.659573  [ 6464/15874]\n",
      "loss: 2.688705  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.1%, Avg loss: 2.668985 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 2.751262  [   64/15874]\n",
      "loss: 2.659212  [ 6464/15874]\n",
      "loss: 2.688326  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.1%, Avg loss: 2.668725 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 2.751242  [   64/15874]\n",
      "loss: 2.658857  [ 6464/15874]\n",
      "loss: 2.687951  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.668470 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 2.751221  [   64/15874]\n",
      "loss: 2.658506  [ 6464/15874]\n",
      "loss: 2.687581  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.668219 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 2.751198  [   64/15874]\n",
      "loss: 2.658160  [ 6464/15874]\n",
      "loss: 2.687216  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.667973 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 2.751174  [   64/15874]\n",
      "loss: 2.657818  [ 6464/15874]\n",
      "loss: 2.686854  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.667731 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 2.751148  [   64/15874]\n",
      "loss: 2.657481  [ 6464/15874]\n",
      "loss: 2.686498  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.667493 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 2.751121  [   64/15874]\n",
      "loss: 2.657148  [ 6464/15874]\n",
      "loss: 2.686145  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.667259 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 2.751092  [   64/15874]\n",
      "loss: 2.656819  [ 6464/15874]\n",
      "loss: 2.685796  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.667028 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 2.751061  [   64/15874]\n",
      "loss: 2.656494  [ 6464/15874]\n",
      "loss: 2.685452  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.666802 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 2.751030  [   64/15874]\n",
      "loss: 2.656174  [ 6464/15874]\n",
      "loss: 2.685112  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.666579 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 2.750997  [   64/15874]\n",
      "loss: 2.655857  [ 6464/15874]\n",
      "loss: 2.684776  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.666360 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 2.750963  [   64/15874]\n",
      "loss: 2.655544  [ 6464/15874]\n",
      "loss: 2.684443  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.1%, Avg loss: 2.666144 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 2.750927  [   64/15874]\n",
      "loss: 2.655235  [ 6464/15874]\n",
      "loss: 2.684115  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.0%, Avg loss: 2.665932 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.750891  [   64/15874]\n",
      "loss: 2.654930  [ 6464/15874]\n",
      "loss: 2.683791  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.1%, Avg loss: 2.665723 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 2.750853  [   64/15874]\n",
      "loss: 2.654629  [ 6464/15874]\n",
      "loss: 2.683470  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.1%, Avg loss: 2.665518 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 2.750814  [   64/15874]\n",
      "loss: 2.654331  [ 6464/15874]\n",
      "loss: 2.683153  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.2%, Avg loss: 2.665315 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 2.750774  [   64/15874]\n",
      "loss: 2.654036  [ 6464/15874]\n",
      "loss: 2.682840  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.2%, Avg loss: 2.665116 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 2.750733  [   64/15874]\n",
      "loss: 2.653745  [ 6464/15874]\n",
      "loss: 2.682530  [12864/15874]\n",
      "Validation Error:\n",
      " Accuracy: 22.1%, Avg loss: 2.664919 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# optimizing model parameters\n",
    "\n",
    "# initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, net, loss_fn, optimizer, device)\n",
    "    (acc, loss) = validate_loop(validate_dataloader, net, loss_fn, device)\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350bc332662a4e40927a7c52d9322c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.023 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.057310…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▂▃▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>loss</td><td>██▇▇▆▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.22132</td></tr><tr><td>loss</td><td>2.66492</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deft-moon-198</strong> at: <a href='https://wandb.ai/gillenpj/horse-racing-project/runs/jazil65d' target=\"_blank\">https://wandb.ai/gillenpj/horse-racing-project/runs/jazil65d</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230508_093852-jazil65d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para_name, para_vals in net.named_parameters():\n",
    "    np.savetxt(\"weights and biases\\\\\" + para_name + \".csv\", para_vals.data.numpy(), fmt='%6.3f', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model for use by Dividend Project Model\n",
    "torch.save(net, \"models\\\\\" + model + \".pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ed282fe5a96d451181bcb846a73bf3735bfa0d466ee57d09e22e537eb2d1df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
