{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This scripts takes about 1 1/2 minutes seconds to execute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea of this notebook is to create a first (simple) DL model using all the same features used in the multinomial logit model.\n",
    "\n",
    "Much inspiration was derived from https://towardsdatascience.com/use-machine-learning-to-predict-horse-racing-4f1111fb6ced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from importlib import reload\n",
    "import deeplearninglib\n",
    "reload(deeplearninglib)\n",
    "from deeplearninglib import *\n",
    "\n",
    "import wandb\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model to train\n",
    "\n",
    "model_inventory = {'mktprob': {'XZ_columns': [\"mkt_prob\"],\n",
    "                               'continuous_features': [\"mkt_prob\"],\n",
    "                               'learning_rate': 10e-1,\n",
    "                               'epochs': 50,\n",
    "                               'vacant_stall_indicator': False,\n",
    "                               'bias': True,\n",
    "                               'model_architecture': LinSig},\n",
    "                   'mktprob_soft': {'XZ_columns': [\"mkt_prob\"],\n",
    "                               'continuous_features': [\"mkt_prob\"],\n",
    "                               'learning_rate': 10e-1,\n",
    "                               'epochs': 50,\n",
    "                               'vacant_stall_indicator': False,\n",
    "                               'bias': True,\n",
    "                               'model_architecture': LinSoft},\n",
    "                    'mktprob_MLR': {'XZ_columns': [\"mkt_prob\"],\n",
    "                               'continuous_features': [\"mkt_prob\"],\n",
    "                               'learning_rate': 10e-1,\n",
    "                               'epochs': 50,\n",
    "                               'vacant_stall_indicator': False,\n",
    "                               'bias': True,\n",
    "                               'model_architecture': MLR},\n",
    "                   'AlunOwen_v0': {'XZ_columns': [\"age\", \"sire_sr\", \"dam_sr\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"visor\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [\"age\", \"sire_sr\", \"dam_sr\", \"trainer_sr\", \"daysLTO\"],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': True,\n",
    "                                   'model_architecture': LinSig},\n",
    "                   'AlunOwen_v1': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [\"age\", \"trainer_sr\", \"daysLTO\"],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': True,\n",
    "                                   'model_architecture': LinSig},\n",
    "                   'AlunOwen_v2': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [\"age\", \"trainer_sr\", \"daysLTO\"],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': True,\n",
    "                                   'model_architecture': LinDropReluLinSoft},\n",
    "                   'AlunOwen_v3': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [\"age\", \"trainer_sr\", \"daysLTO\"],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': False,\n",
    "                                   'model_architecture': MLR},\n",
    "                   'AlunOwen_v4': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\"],\n",
    "                                   'continuous_features': [],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': False,\n",
    "                                   'model_architecture': MLR},\n",
    "                   'test_v1': {'XZ_columns': [\"age\", \"trainer_sr\", \"daysLTO\", \"position1_1\", \"position1_2\", \"position1_3\", \"position1_4\", \"position2_1\", \"position2_2\", \"position2_3\", \"position2_4\", \"position3_1\", \"position3_2\", \"position3_3\", \"position3_4\", \"entire\", \"gelding\", \"blinkers\", \"cheekpieces\", \"tonguetie\", \"course_Kempton\", \"course_Lingfield\", \"course_Southwell\", \"course_Wolverhampton\", \"going_Firm\", \"going_Good\", \"going_Good to Firm\", \"going_Good to Soft\", \"going_Slow\", \"going_Soft\", \"going_Standard\", \"going_Standard to Slow\", \"direction_Left Handed\", \"direction_Right Handed\"],\n",
    "                                   'continuous_features': [],\n",
    "                                   'learning_rate': 10e-3,\n",
    "                                   'epochs': 100,\n",
    "                                   'vacant_stall_indicator': False,\n",
    "                                   'bias': False,\n",
    "                                   'model_architecture': LinDropReluLinSoft}\n",
    "                               }\n",
    "\n",
    "model = 'AlunOwen_v3'\n",
    "XZ_columns = model_inventory[model]['XZ_columns']\n",
    "continuous_features = model_inventory[model]['continuous_features']\n",
    "learning_rate = model_inventory[model]['learning_rate']\n",
    "epochs = model_inventory[model]['epochs']\n",
    "vacant_stall_indicator = model_inventory[model]['vacant_stall_indicator']\n",
    "bias = model_inventory[model]['bias']\n",
    "model_architecture = model_inventory[model]['model_architecture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "y_columns = [\"win\"] # assumed to be contained in runners files\n",
    "\n",
    "runners_train_data_fn = \"data\\\\runners_train.csv\"\n",
    "races_train_data_fn = \"data\\\\races_train.csv\"\n",
    "runners_validate_data_fn = \"data\\\\runners_validate.csv\"\n",
    "races_validate_data_fn = \"data\\\\races_validate.csv\"\n",
    "\n",
    "train_data = RacesDataset(runners_train_data_fn, races_train_data_fn, XZ_columns, y_columns, vacant_stall_indicator=vacant_stall_indicator, continuous_features=continuous_features)\n",
    "validate_data = RacesDataset(runners_validate_data_fn, races_validate_data_fn, XZ_columns, y_columns, vacant_stall_indicator=vacant_stall_indicator, scalar=train_data.scalar, continuous_features=continuous_features)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "validate_dataloader = DataLoader(validate_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare and save test data for use by Dividend Project Model; then delete them to ensure they're not used during training or validation\n",
    "\n",
    "# note, test data is model-specific\n",
    "\n",
    "runners_test_data_fn = \"data\\\\runners_test.csv\"\n",
    "races_test_data_fn = \"data\\\\races_test.csv\"\n",
    "\n",
    "test_data = RacesDataset(runners_test_data_fn, races_test_data_fn, XZ_columns, y_columns, vacant_stall_indicator=vacant_stall_indicator, scalar=train_data.scalar, continuous_features=continuous_features)\n",
    "\n",
    "torch.save(test_data, \"data\\\\\" + model + \"_test_data.pt\")\n",
    "\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000 # was 20\n",
    "train_data.runners_wide.loc[:, train_data.X_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model_architecture != \"MLR\" or train_data.races is None, \"Use of MLR with race-specific variables isn't yet supported\"\n",
    "train_data.races.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the neural network\n",
    "\n",
    "output_layer_nodes = train_data.y.shape[1]\n",
    "if train_data.Z is not None:\n",
    "    input_layer_nodes = train_data.X.shape[1] + train_data.Z.shape[1]\n",
    "else:\n",
    "    input_layer_nodes = train_data.X.shape[1]\n",
    "\n",
    "torch.manual_seed(0)\n",
    "net = model_architecture(input_layer_nodes, output_layer_nodes, bias=bias).to(device) # linear-relu-linear-softwax nn (1 hidden layer)\n",
    "print(f\"Model structure: {model}\")\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example to show how model is used from prediction\n",
    "\n",
    "inputs = torch.rand(1, input_layer_nodes, device=device)\n",
    "logits = net(inputs)\n",
    "y_pred = logits.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env WANDB_NOTEBOOK_NAME 'C:\\Users\\gille\\OneDrive\\1-Projects\\_Horse Racing 2H22\\New Framework\\3b_Deep Learning.ipynb'\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"horse-racing-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"device\": device,\n",
    "    \"model\": model,\n",
    "    \"XZ_columns\": XZ_columns,\n",
    "    \"continuous_featurs\": continuous_features,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epochs\": epochs,\n",
    "    \"vacant_stall_indicator\": vacant_stall_indicator,\n",
    "    \"bias\": bias,\n",
    "    \"model_architecture\": list(net.modules())\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing model parameters\n",
    "\n",
    "# initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, net, loss_fn, optimizer, device)\n",
    "    (acc, loss) = validate_loop(validate_dataloader, net, loss_fn, device)\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para_name, para_vals in net.named_parameters():\n",
    "    np.savetxt(\"weights and biases\\\\\" + para_name + \".csv\", para_vals.data.numpy(), fmt='%6.3f', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model for use by Dividend Project Model\n",
    "torch.save(net, \"models\\\\\" + model + \".pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4ed282fe5a96d451181bcb846a73bf3735bfa0d466ee57d09e22e537eb2d1df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
